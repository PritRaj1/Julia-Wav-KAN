[optimizer]
step_rate=33
learning_rate=0.0039530152996991134
gamma=0.24847258887791046
min_lr=0.0001
type=adam

[architecture]
d_model=142
nhead=11
dropout=0.4721895004747526
max_len=1131
num_decoder_layers=3
num_encoder_layers=7
dim_feedforward=973
activation=relu

[pipeline]
num_epochs=50

[loss]
p=2.0

[dataloader]
batch_size=17

