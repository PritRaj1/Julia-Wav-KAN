[optimizer]
step_rate=35
learning_rate=0.09636304542122444
gamma=0.614567622906606
min_lr=0.0001
type=adam

[architecture]
d_model=66
nhead=20
dropout=0.5136100357965112
max_len=2617
num_decoder_layers=1
num_encoder_layers=2
dim_feedforward=1124
activation=relu

[pipeline]
num_epochs=50

[loss]
p=2.0

[dataloader]
batch_size=1

