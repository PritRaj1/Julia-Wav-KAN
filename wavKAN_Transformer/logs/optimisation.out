┌ Warning: CUDA runtime library `libcublasLt.so.12` was loaded from a system path, `/usr/local/cuda-12.3/lib64/libcublasLt.so.12`.
│ 
│ This may cause errors. Ensure that you have not set the LD_LIBRARY_PATH
│ environment variable, or that it does not contain paths to CUDA libraries.
│ 
│ In any other case, please file an issue.
└ @ CUDA ~/.julia/packages/CUDA/75aiI/src/initialization.jl:219
┌ Warning: CUDA runtime library `libnvJitLink.so.12` was loaded from a system path, `/usr/local/cuda-12.3/lib64/libnvJitLink.so.12`.
│ 
│ This may cause errors. Ensure that you have not set the LD_LIBRARY_PATH
│ environment variable, or that it does not contain paths to CUDA libraries.
│ 
│ In any other case, please file an issue.
└ @ CUDA ~/.julia/packages/CUDA/75aiI/src/initialization.jl:219
┌ Warning: CUDA runtime library `libcusparse.so.12` was loaded from a system path, `/usr/local/cuda-12.3/lib64/libcusparse.so.12`.
│ 
│ This may cause errors. Ensure that you have not set the LD_LIBRARY_PATH
│ environment variable, or that it does not contain paths to CUDA libraries.
│ 
│ In any other case, please file an issue.
└ @ CUDA ~/.julia/packages/CUDA/75aiI/src/initialization.jl:219
ERROR: LoadError: Out of GPU memory trying to allocate 983.808 MiB
Effective GPU memory usage: 99.95% (47.502 GiB/47.528 GiB)
Memory pool usage: 46.158 GiB (47.188 GiB reserved)

Stacktrace:
  [1] _pool_alloc
    @ ~/.julia/packages/CUDA/75aiI/src/memory.jl:660 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/75aiI/src/memory.jl:617 [inlined]
  [3] macro expansion
    @ ./timing.jl:395 [inlined]
  [4] pool_alloc
    @ ~/.julia/packages/CUDA/75aiI/src/memory.jl:616 [inlined]
  [5] CuArray{Float32, 4, CUDA.DeviceMemory}(::UndefInitializer, dims::NTuple{4, Int64})
    @ CUDA ~/.julia/packages/CUDA/75aiI/src/array.jl:74
  [6] similar
    @ ./abstractarray.jl:877 [inlined]
  [7] similar
    @ ./abstractarray.jl:876 [inlined]
  [8] similar
    @ ~/.julia/packages/CUDA/75aiI/src/broadcast.jl:25 [inlined]
  [9] similar
    @ ./broadcast.jl:223 [inlined]
 [10] copy
    @ ~/.julia/packages/GPUArrays/HjWFN/src/host/broadcast.jl:29 [inlined]
 [11] materialize
    @ ./broadcast.jl:903 [inlined]
 [12] broadcast_preserving_zero_d
    @ ./broadcast.jl:892 [inlined]
 [13] -(A::CuArray{Float32, 4, CUDA.DeviceMemory}, B::CuArray{Float32, 4, CUDA.DeviceMemory})
    @ Base ./arraymath.jl:8
 [14] adjoint
    @ ~/.julia/packages/Zygote/nsBv0/src/lib/array.jl:652 [inlined]
 [15] _pullback(__context__::Zygote.Context{false}, 571::typeof(-), A::CuArray{Float32, 4, CUDA.DeviceMemory}, B::CuArray{Float32, 4, CUDA.DeviceMemory})
    @ Zygote ~/.julia/packages/ZygoteRules/M4xmc/src/adjoint.jl:67
 [16] KANdense_layer
    @ ~/repos/Julia-Wav-KAN/KAN/KAN_layers.jl:80 [inlined]
 [17] _pullback(ctx::Zygote.Context{false}, f::Main.KANTransformerModel.KAN_Transform_Layers.layers.KANdense_layer, args::CuArray{Float32, 3, CUDA.DeviceMemory})
    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0
 [18] encoder_layer
    @ ~/repos/Julia-Wav-KAN/wavKAN_Transformer/Klayers.jl:83 [inlined]
 [19] _pullback(ctx::Zygote.Context{false}, f::Main.KANTransformerModel.KAN_Transform_Layers.encoder_layer, args::CuArray{Float32, 3, CUDA.DeviceMemory})
    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0
 [20] KAN_Transformer
    @ ~/repos/Julia-Wav-KAN/wavKAN_Transformer/KAN_Transformer.jl:68 [inlined]
 [21] _pullback(::Zygote.Context{false}, ::Main.KANTransformerModel.KAN_Transformer, ::CuArray{Float32, 2, CUDA.DeviceMemory}, ::CuArray{Float32, 2, CUDA.DeviceMemory})
    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0
 [22] loss_fcn
    @ ~/repos/Julia-Wav-KAN/utils.jl:12 [inlined]
 [23] _pullback(::Zygote.Context{false}, ::typeof(loss_fcn), ::Main.KANTransformerModel.KAN_Transformer, ::CuArray{Float32, 2, CUDA.DeviceMemory}, ::CuArray{Float32, 2, CUDA.DeviceMemory})
    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0
 [24] #1
    @ ~/repos/Julia-Wav-KAN/pipeline/train.jl:20 [inlined]
 [25] _pullback(ctx::Zygote.Context{false}, f::Main.training.var"#1#2"{typeof(loss_fcn), CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}}, args::Main.KANTransformerModel.KAN_Transformer)
    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0
 [26] pullback(f::Function, cx::Zygote.Context{false}, args::Main.KANTransformerModel.KAN_Transformer)
    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface.jl:90
 [27] pullback
    @ ~/.julia/packages/Zygote/nsBv0/src/compiler/interface.jl:88 [inlined]
 [28] withgradient(f::Function, args::Main.KANTransformerModel.KAN_Transformer)
    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface.jl:205
 [29] train_step(m::Main.KANTransformerModel.KAN_Transformer, opt_state::@NamedTuple{position_encoding::@NamedTuple{pe_vector::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, encoder::Vector{@NamedTuple{self_attn::@NamedTuple{Wq::@NamedTuple{transform::@NamedTuple{weights::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, output_layer::Tuple{}, norm::Tuple{}, scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, translation::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, reshape_fcn::Tuple{}, norm_permute::Tuple{}}, Wk::@NamedTuple{transform::@NamedTuple{weights::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, output_layer::Tuple{}, norm::Tuple{}, scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, translation::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, reshape_fcn::Tuple{}, norm_permute::Tuple{}}, Wv::@NamedTuple{transform::@NamedTuple{weights::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, output_layer::Tuple{}, norm::Tuple{}, scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, translation::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, reshape_fcn::Tuple{}, norm_permute::Tuple{}}, sqrt_D::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, query_M::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, feed_forward::Vector{NamedTuple}, norm1::@NamedTuple{λ::Tuple{}, diag::@NamedTuple{scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, σ::Tuple{}}, ϵ::Tuple{}, size::Tuple{Tuple{}}, affine::Tuple{}}, norm2::@NamedTuple{λ::Tuple{}, diag::@NamedTuple{scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, σ::Tuple{}}, ϵ::Tuple{}, size::Tuple{Tuple{}}, affine::Tuple{}}}}, decoder::Vector{@NamedTuple{mh_attn::@NamedTuple{Wq::@NamedTuple{transform::@NamedTuple{weights::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, output_layer::Tuple{}, norm::Tuple{}, scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, translation::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, reshape_fcn::Tuple{}, norm_permute::Tuple{}}, Wk::@NamedTuple{transform::@NamedTuple{weights::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, output_layer::Tuple{}, norm::Tuple{}, scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, translation::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, reshape_fcn::Tuple{}, norm_permute::Tuple{}}, Wv::@NamedTuple{transform::@NamedTuple{weights::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, output_layer::Tuple{}, norm::Tuple{}, scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, translation::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, reshape_fcn::Tuple{}, norm_permute::Tuple{}}, sqrt_D::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, query_M::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, feed_forward::Vector{NamedTuple}, norm1::@NamedTuple{λ::Tuple{}, diag::@NamedTuple{scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, σ::Tuple{}}, ϵ::Tuple{}, size::Tuple{Tuple{}}, affine::Tuple{}}, norm2::@NamedTuple{λ::Tuple{}, diag::@NamedTuple{scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, σ::Tuple{}}, ϵ::Tuple{}, size::Tuple{Tuple{}}, affine::Tuple{}}, norm3::@NamedTuple{λ::Tuple{}, diag::@NamedTuple{scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 1, CUDA.DeviceMemory}, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, σ::Tuple{}}, ϵ::Tuple{}, size::Tuple{Tuple{}}, affine::Tuple{}}}}, output_layer::@NamedTuple{transform::@NamedTuple{weights::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}}, output_layer::Tuple{}, norm::Tuple{}, scale::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, translation::Optimisers.Leaf{Optimisers.Adam, Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}, Tuple{Float32, Float32}}}, reshape_fcn::Tuple{}, norm_permute::Tuple{}}}, train_loader::MLUtils.DataLoader{Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}}, Random._GLOBAL_RNG, Val{nothing}}, test_loader::MLUtils.DataLoader{Tuple{CuArray{Float32, 2, CUDA.DeviceMemory}, CuArray{Float32, 2, CUDA.DeviceMemory}}, Random._GLOBAL_RNG, Val{nothing}}, loss::typeof(loss_fcn), epoch::Int64)
    @ Main.training ~/repos/Julia-Wav-KAN/pipeline/train.jl:20
 [30] objective(trial::HyperTuning.Trial{Int64})
    @ Main ~/repos/Julia-Wav-KAN/wavKAN_Transformer/hyperparamter_tuning.jl:91
 [31] evaluate_trial!(f::typeof(objective), trial::HyperTuning.Trial{Int64}, verbose::Bool)
    @ HyperTuning ~/.julia/packages/HyperTuning/7Qthr/src/evaluator/sequential.jl:5
 [32] evaluate_objective_sequential(f::Function, scenario::Scenario)
    @ HyperTuning ~/.julia/packages/HyperTuning/7Qthr/src/evaluator/sequential.jl:27
 [33] evaluate_objective
    @ ~/.julia/packages/HyperTuning/7Qthr/src/evaluator/evaluate_objective.jl:12 [inlined]
 [34] optimize!(f::Function, scenario::Scenario)
    @ HyperTuning ~/.julia/packages/HyperTuning/7Qthr/src/optimize.jl:29
 [35] optimize(f::Function, scenario::Scenario)
    @ HyperTuning ~/.julia/packages/HyperTuning/7Qthr/src/optimize.jl:47
 [36] top-level scope
    @ ~/repos/Julia-Wav-KAN/wavKAN_Transformer/hyperparamter_tuning.jl:142
in expression starting at /home/pr478/repos/Julia-Wav-KAN/wavKAN_Transformer/hyperparamter_tuning.jl:142
